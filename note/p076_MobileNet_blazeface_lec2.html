<!DOCTYPE html>
<html lang="ko">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Document</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7/dist/blazeface.min.js"></script>
  <style>
    canvas,
    video {
      position: absolute;
    }
  </style>
</head>

<body>
  <h1>웹캠 얼굴</h1>
  <hr>
  <button id="btn1" onclick="main()">스캔시작</button>
  <button id="btn2" onclick="face()">얼굴인식시작</button>
  <p id="predictions">버튼을 누르세요.</p>
  <div id="display">
    <video src="" width="500" height="500"></video>
    <canvas width="500" height="500"></canvas>
  </div>
  <script>
    const video = document.querySelector("video");
    const pp = document.getElementById("predictions");
    const canvas = document.querySelector("canvas");
    const ctx = canvas.getContext("2d");
    const main = async () => {
      const cam = await tf.data.webcam(video);
      const img = await cam.capture();
      const model = await mobilenet.load()
      const predictions = await model.classify(img)
      console.log(predictions);
      pp.innerHTML =
        predictions[0].className +
        "<br>" +
        (predictions[0].probability * 100).toFixed(2) +
        "%";
    };
    const face = async () => {
      const cam = await tf.data.webcam(video);
      const img = await cam.capture();
      blaze = await blazeface.load();
      const predictions = await blaze.estimateFaces(img);
      console.log(predictions)
      // 인원수 표시
      pp.innerHTML = `측정인원수: ${predictions.length}명`;
      // 캔버스 초기화
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // 얼굴 사각형 그리기
      predictions.forEach(pred => {
        const [x, y] = pred.topLeft;
        const [x2, y2] = pred.bottomRight;
        const w = x2 - x, h = y2 - y;
        ctx.strokeStyle = "cornflowerblue";
        ctx.lineWidth = 2;
        ctx.strokeRect(x, y, w, h);
      });
    }
  </script>
  <script>
    // 출력: 얼굴이 감지된 경우, 각 얼굴에 대해 다음 정보를 포함한 배열 반환
    // topLeft: 얼굴 영역의 좌상단 좌표
    // bottomRight: 얼굴 영역의 우하단 좌표
    // landmarks: 눈, 코, 입, 귀 등 6개의 얼굴 특징점 좌표
    // probability: 얼굴일 확률 (0~1 사이 값)
  </script>
</body>

</html>