<!DOCTYPE html>
<html lang="ko">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Document</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7/dist/blazeface.min.js"></script>
  <style>
    #display {
      float: left;
    }
  </style>
</head>


<body>
  <h1>웹캠 얼굴</h1>
  <hr>
  <button id="btn2" onclick="face()">얼굴인식시작</button>
  <button id="shot" onclick="shot()">찰칵</button>
  <p id="predictions">버튼을 누르세요.</p>
  <hr>
  <div id="display">
    <video src="" width="500" height="500"></video>
    <canvas width="500" height="500"></canvas>
  </div>
  <script>
    const video = document.querySelector("video");
    const canvas = document.querySelector("canvas");
    const face = async () => {
      const cam = await tf.data.webcam(video);
      const img = await cam.capture();
      console.log(img)
      blaze = await blazeface.load();
      const predictions = await blaze.estimateFaces(img);
      console.log(predictions)
      tf.dispose(img);
    }
    const shot = async () => {
      const cam = await tf.data.webcam(video);
      const img = await cam.capture();
      await tf.browser.toPixels(img, canvas);
      // 1) 1차원 배열로 모든 값 반환 (비동기)
      // const flatData = await img.data();
      // console.log(flatData);
      // 2) 다차원 배열로 변환 (비동기)
      const arr = await img.array();
      console.log(arr);
    }
  </script>
  <script>
    // 출력: 얼굴이 감지된 경우, 각 얼굴에 대해 다음 정보를 포함한 배열 반환
    // topLeft: 얼굴 영역의 좌상단 좌표
    // bottomRight: 얼굴 영역의 우하단 좌표
    // landmarks: 눈, 코, 입, 귀 등 6개의 얼굴 특징점 좌표
    // probability: 얼굴일 확률 (0~1 사이 값)
  </script>
</body>

</html>